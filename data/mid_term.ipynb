{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RSoJ_fICVb4"
   },
   "source": [
    "1. 데이터 불러오기/정보/결측치 확인\n",
    "2. 데이터 전처리\n",
    "3. 훈련/테스트 세트로 데이터 분리\n",
    "4. 모델 컴파일 및 학습\n",
    "5. 손실 및 정확도,예측 등 결과 확인 및 분석\n",
    "6. 성능 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51zuYOsfPQ96"
   },
   "source": [
    "1-1. 기본적인 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "XJ3fpWQZCLBo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlJ8rBAqPXo_"
   },
   "source": [
    "1-2. CSV 파일 불러오고, 파일 정보 및 이상치 탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "aa-ALuU7Pgzg",
    "outputId": "45d14236-97c1-42e8-8b3a-8607ef2be122"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>4172</td>\n",
       "      <td>F</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>4173</td>\n",
       "      <td>M</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>4174</td>\n",
       "      <td>M</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>4175</td>\n",
       "      <td>F</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>4176</td>\n",
       "      <td>M</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0        0   M   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1        1   M   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2        2   F   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3        3   M   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4        4   I   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...    ...  ..     ...       ...     ...           ...             ...   \n",
       "4172  4172   F   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173  4173   M   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174  4174   M   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175  4175   F   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176  4176   M   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "...              ...           ...    ...  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[4177 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('abalone.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hwgY2hbQRdG",
    "outputId": "105b7d68-c7ab-4247-cef9-f6e28cef643a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              4177 non-null   int64  \n",
      " 1   Sex             4177 non-null   object \n",
      " 2   Length          4177 non-null   float64\n",
      " 3   Diameter        4177 non-null   float64\n",
      " 4   Height          4177 non-null   float64\n",
      " 5   Whole_weight    4177 non-null   float64\n",
      " 6   Shucked_weight  4177 non-null   float64\n",
      " 7   Viscera_weight  4177 non-null   float64\n",
      " 8   Shell_weight    4177 non-null   float64\n",
      " 9   Rings           4177 non-null   int64  \n",
      "dtypes: float64(7), int64(2), object(1)\n",
      "memory usage: 326.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# 데이터 파일 기본 정보 확인\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "pT6B4ZTzQY5D",
    "outputId": "47729d61-167e-4a33-dda6-3fb5e40e1abf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "      <td>4177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2088.000000</td>\n",
       "      <td>0.523992</td>\n",
       "      <td>0.407881</td>\n",
       "      <td>0.139516</td>\n",
       "      <td>0.828742</td>\n",
       "      <td>0.359367</td>\n",
       "      <td>0.180594</td>\n",
       "      <td>0.238831</td>\n",
       "      <td>9.933684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1205.940366</td>\n",
       "      <td>0.120093</td>\n",
       "      <td>0.099240</td>\n",
       "      <td>0.041827</td>\n",
       "      <td>0.490389</td>\n",
       "      <td>0.221963</td>\n",
       "      <td>0.109614</td>\n",
       "      <td>0.139203</td>\n",
       "      <td>3.224169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1044.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2088.000000</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3132.000000</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>1.153000</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.329000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4176.000000</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>2.825500</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       Length     Diameter       Height  Whole_weight  \\\n",
       "count  4177.000000  4177.000000  4177.000000  4177.000000   4177.000000   \n",
       "mean   2088.000000     0.523992     0.407881     0.139516      0.828742   \n",
       "std    1205.940366     0.120093     0.099240     0.041827      0.490389   \n",
       "min       0.000000     0.075000     0.055000     0.000000      0.002000   \n",
       "25%    1044.000000     0.450000     0.350000     0.115000      0.441500   \n",
       "50%    2088.000000     0.545000     0.425000     0.140000      0.799500   \n",
       "75%    3132.000000     0.615000     0.480000     0.165000      1.153000   \n",
       "max    4176.000000     0.815000     0.650000     1.130000      2.825500   \n",
       "\n",
       "       Shucked_weight  Viscera_weight  Shell_weight        Rings  \n",
       "count     4177.000000     4177.000000   4177.000000  4177.000000  \n",
       "mean         0.359367        0.180594      0.238831     9.933684  \n",
       "std          0.221963        0.109614      0.139203     3.224169  \n",
       "min          0.001000        0.000500      0.001500     1.000000  \n",
       "25%          0.186000        0.093500      0.130000     8.000000  \n",
       "50%          0.336000        0.171000      0.234000     9.000000  \n",
       "75%          0.502000        0.253000      0.329000    11.000000  \n",
       "max          1.488000        0.760000      1.005000    29.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QpQMqKl2Qs3q",
    "outputId": "b2face7a-417f-4e85-cafa-14cbd813e9bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 결측치 확인 값이 False라면 Null 값이 없는거고 True면 있는거니깐\n",
    "# 해당 행을 제거해주거나 그 열에 해당하는 평균 값을 넣어주기\n",
    "\n",
    "df.isnull().values.any()\n",
    "\n",
    "# # 결측치가 있는 행을 제거하려면\n",
    "# df = df.dropna()\n",
    "\n",
    "# # 결측치를 열의 평균값으로 채우려면\n",
    "# df = df.fillna(df.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1HPTaQ1StkS"
   },
   "source": [
    "2-1. 문제에 맞는(지도 학습 -분류/회귀, 비지도 학습 - PCA/AutoEncoder) input, target으로 데이터 전처리 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hAtxXsnmTZe3"
   },
   "outputs": [],
   "source": [
    "# 전복 csv 데이터 기준으로, 분류 문제는 성별을 맞추는 것, 회귀 문제는 Rings 값을 예측하는 것으로 함\n",
    "\n",
    "# .values를 넣어 csv 데이터를 넘파이 배열로 바꿔줘야함\n",
    "\n",
    "# 분류인 경우 target 값은 성별이 됨.\n",
    "input = df.drop(['id','Sex'],axis=1).values\n",
    "target = df['Sex']\n",
    "\n",
    "# 회귀인 경우 target 값은 Rings가 됨.\n",
    "# input = df.drop(['id','Rings'],axis=1).values\n",
    "# target = df['Rings']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "B3HpaZPXU8c2"
   },
   "outputs": [],
   "source": [
    "# 단, 조건에 맞는 열만 가지고 문제를 수행하라 할 수 도 있음\n",
    "# 전복 데이터 중 Length, Height, Diameter 만 가지고 수행하라\n",
    "\n",
    "df = df[['Length','Height','Diameter']]\n",
    "\n",
    "# 분류 문제에서 target 값이 여러 개가 있을 수 있는데, 그 때 필요한 target 만 쓰라하면\n",
    "# isin 이라는 함수를 통해 원하는 값의 행 만 추출할 수 있음(전복의 성은 M,F,I 3개 가 있음)\n",
    "#df = df[df['Sex'].isin(['M', 'F'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eujIjsfkXl7s"
   },
   "source": [
    "2-2. 입력 데이터 또는 정답 데이터에 수치형 데이터가 아닌 범주형 데이터가 있다면 라벨 인코딩 또는 원-핫 인코딩을 수행해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "t0iwsuBwXwrN"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# target 을 수치형 데이터로 바꿔주기\n",
    "le = LabelEncoder()\n",
    "target = le.fit_transform(target)\n",
    "\n",
    "# 만약 input에 범주형 데이터가 있다면 필요한 열에 대해서 원-핫 인코딩을 수행해준다.\n",
    "# df = pd.get_dummies(df,columns=['Sex']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "uHXZEy2feJ10"
   },
   "outputs": [],
   "source": [
    "# 만약 오토인코더 문제에서 'activity' 열 전처리: lyingBack, lyingRigh -> 정상 (0), sitting -> 비정상 (1)\n",
    "# 이러한 유형의 경우는 이렇게 replace를 쓰면 된다,\n",
    "\n",
    "# df['activity'] = df['activity'].replace({'lyingBack': 0, 'lyingRigh': 0, 'sitting': 1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snRFkxvbfQK-"
   },
   "source": [
    "2-3. 내가 원하는 데이터를이 최종적으로 잘 추출되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "sr5hvyc7fTvh"
   },
   "outputs": [],
   "source": [
    "# unique,shape,value_counts 로 확인 해보기\n",
    "\n",
    "# df['Sex'].unique(), df.shape, df['Sex'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfrAy8j-fpot"
   },
   "source": [
    "3-1. 데이터를 train,valid,test 로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "KVNdh8zsfuF5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train/test 분리\n",
    "x_train ,x_test, y_train, y_test = train_test_split (input,target, test_size=0.2,stratify=target)\n",
    "# train/valid 분리\n",
    "x_train ,x_valid, y_train, y_valid = train_test_split (x_train,y_train, test_size=0.2,stratify=y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skck26l5grtb"
   },
   "source": [
    "3-2. 데이터의 정규화를 위해 StandardScaler 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "v2M9AiOdgw2F"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# train 에 대해서한 fit_transform을 적용하며, valid,test는 train에 맞게 transform만 하면 된다.\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_valid = ss.transform(x_valid)\n",
    "x_test = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1YkP2XmhFiG"
   },
   "source": [
    "4-1. 모델 만들기 - 머신러닝 분류\n",
    "\n",
    "Logistic Regression, Decision Tree, Support Vector Classifier, KNN , Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "blmJhbk3j-aO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5729665071770335\n",
      "0.45933014354066987\n",
      "0.5538277511961722\n",
      "0.5203349282296651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jongmin\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5502392344497608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 로지스틱 리그레션\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "lr_pred = lr.predict(x_test)\n",
    "lr_acc = accuracy_score(y_test,lr_pred)\n",
    "print(lr_acc)\n",
    "\n",
    "# 의사결정트리\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)\n",
    "dt_pred = dt.predict(x_test)\n",
    "dt_acc = accuracy_score(y_test,dt_pred)\n",
    "print(dt_acc)\n",
    "\n",
    "# 서포트 벡터\n",
    "svc = SVC()\n",
    "svc.fit(x_train,y_train)\n",
    "svc_pred = svc.predict(x_test)\n",
    "svc_acc = accuracy_score(y_test,svc_pred)\n",
    "print(svc_acc)\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train,y_train)\n",
    "knn_pred = knn.predict(x_test)\n",
    "knn_acc = accuracy_score(y_test,knn_pred)\n",
    "print(knn_acc)\n",
    "\n",
    "# 랜덤 포레스트\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train,y_train)\n",
    "rf_pred = rf.predict(x_test)\n",
    "rf_acc = accuracy_score(y_test,rf_pred)\n",
    "print(rf_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JM70DadCiulE"
   },
   "source": [
    "4-1. 모델 만들기- 머신러닝 회귀\n",
    "\n",
    "Linear Regression, Random Forest, Decision Tree,Support Vector Regression, KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "WpjMW1cAkAJY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6722318518005005\n",
      "1.4270334928229664\n",
      "0.7429005317357922\n",
      "0.8031100478468901\n",
      "0.7234633971291865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 선형 회귀\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "lr_pred = lr.predict(x_test)\n",
    "lr_mse = mean_squared_error(y_test,lr_pred)\n",
    "print(lr_mse)\n",
    "\n",
    "# 의사결정트리\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(x_train,y_train)\n",
    "dt_pred = dt.predict(x_test)\n",
    "dt_mse = mean_squared_error(y_test,dt_pred)\n",
    "print(dt_mse)\n",
    "\n",
    "# 서포트 벡터\n",
    "svr = SVR()\n",
    "svr.fit(x_train,y_train)\n",
    "svr_pred = svr.predict(x_test)\n",
    "svr_mse = mean_squared_error(y_test,svr_pred)\n",
    "print(svr_mse)\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(x_train,y_train)\n",
    "knn_pred = knn.predict(x_test)\n",
    "knn_mse = mean_squared_error(y_test,knn_pred)\n",
    "print(knn_mse)\n",
    "\n",
    "# 랜덤 트리\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(x_train,y_train)\n",
    "rf_pred = rf.predict(x_test)\n",
    "rf_mse = mean_squared_error(y_test,rf_pred)\n",
    "print(rf_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6T3JD1dkEaL"
   },
   "source": [
    "4-1. 딥러닝 모델 만들기(Dense,CNN,LSTM,Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "fvCruXeikOcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 64)                576       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,689\n",
      "Trainable params: 2,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dense 모델\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "input_dim=x_train.shape[1]\n",
    "\n",
    "def create_dense_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # 이진 분류일 경우\n",
    "\n",
    "    # model.add(Dense(10, activation='softmax'))  # 다중 분류일 경우\n",
    "\n",
    "    # model.add(Dense(1))  # 회귀일 경우\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # 다중 분류일 경우(target을 원 핫 인코딩 한 경우)\n",
    "    # model.compile(optimizer='adam', loss='spares_categorical_crossentropy', metrics=['accuracy'])  # 다중 분류일 경우(target을 라벨 인코딩 한 경우)\n",
    "\n",
    "    # model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])  # 회귀일 경우\n",
    "    return model\n",
    "\n",
    "model = create_dense_model((input_dim,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "PctVwrzymJuT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 6, 32)             128       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 3, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                6208      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,401\n",
      "Trainable params: 6,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN 모델\n",
    "\n",
    "# CNN 모델은 기본적으로 3차원 이상의 데이터를 입력으로 받기 때문에\n",
    "# 필요에 맞게 입력 데이터의 차원을 늘려주어야 한다. 4차원Conv2D를 쓰려면 더 추가!\n",
    "\n",
    "# train,valid,test에 대해 동일하게 수행\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))  # 1D 합성곱\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # 이진 분류일 경우\n",
    "\n",
    "    # model.add(Dense(10, activation='softmax'))  # 다중 분류일 경우\n",
    "\n",
    "    # model.add(Dense(1))  # 회귀일 경우\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # 다중 분류일 경우(target을 원 핫 인코딩 한 경우)\n",
    "    # model.compile(optimizer='adam', loss='spares_categorical_crossentropy', metrics=['accuracy'])  # 다중 분류일 경우(target을 라벨 인코딩 한 경우)\n",
    "\n",
    "    # model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])  # 회귀일 경우\n",
    "    return model\n",
    "\n",
    "model = create_cnn_model((x_train.shape[1], 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "NQSKd4jxqU2g"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_32108\\1902726976.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# 타깃값을 맨 뒤에 붙이기 그래야 함수안에 들어가서 x y 로 나눠줄수가 있음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mn_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\index_tricks.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "# LSTM 모델\n",
    "# 시계열 데이터가 필요하므로 데이터를 전처리 해줘야한다.\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def split_sequences(sequences, n_steps):\n",
    "    x, y = list(), list()  # 빈 리스트를 생성하여 시퀀스 데이터와 레이블을 담을 공간을 만듦\n",
    "    for i in range(len(sequences)):  # 전체 시퀀스 데이터를 순회\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps  # 현재 인덱스(i)에서 n_steps만큼 떨어진 시퀀스의 끝을 계산\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):  # 시퀀스 끝이 데이터의 범위를 넘어서는지 확인\n",
    "            break  # 범위를 넘으면 루프 종료\n",
    "        # gather input (X) and output parts (y)\n",
    "        seq_x = sequences[i:end_ix, :-1]  # 입력 데이터 (특징 데이터)\n",
    "        seq_y_values = sequences[i:end_ix, -1]  # 시퀀스 동안의 출력 데이터 (레이블들)\n",
    "\n",
    "        # 가장 빈번하게 나온 레이블 찾기\n",
    "        most_common_label = Counter(seq_y_values).most_common(1)[0][0]\n",
    "\n",
    "        x.append(seq_x)  # 입력 데이터 추가\n",
    "        y.append(most_common_label)  # 가장 많이 나온 레이블 추가\n",
    "\n",
    "    return np.array(x), np.array(y)  # 리스트를 numpy 배열로 변환하여 반환.\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# 타깃값을 맨 뒤에 붙이기 그래야 함수안에 들어가서 x y 로 나눠줄수가 있음\n",
    "train_set = np.c_[x_train, y_train]\n",
    "\n",
    "n_steps = 3\n",
    "x_train, y_train = split_sequences(train_set, n_steps)\n",
    "\n",
    "# 이후 분류 문제에 따라 y_train을 인코딩해주기!\n",
    "\n",
    "# Define the input shape\n",
    "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # 이진 분류일 경우\n",
    "\n",
    "    # model.add(Dense(10, activation='softmax'))  # 다중 분류일 경우\n",
    "\n",
    "    # model.add(Dense(1))  # 회귀일 경우\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # 다중 분류일 경우(target을 원 핫 인코딩 한 경우)\n",
    "    # model.compile(optimizer='adam', loss='spares_categorical_crossentropy', metrics=['accuracy'])  # 다중 분류일 경우(target을 라벨 인코딩 한 경우)\n",
    "\n",
    "    # model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])  # 회귀일 경우\n",
    "    return model\n",
    "\n",
    "model = create_lstm_model((n_timesteps, n_features))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xz3l_8O4wsis"
   },
   "outputs": [],
   "source": [
    "# 트랜스포터 모델, LSTM 모델과 같이 입력 3차원으로 넣어주기\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Attention and Normalization\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "# 문제에 맞는 손실함수 고를것\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4pg0KcjxvKn"
   },
   "source": [
    "4-2. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUj28OR4xxL_"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wN_gi_6MyHGo"
   },
   "source": [
    "5-1. 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRWoSxwxyJo_"
   },
   "outputs": [],
   "source": [
    "# 손실 시각화\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, loss, 'b-', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r-', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIzXCSWGyPRw"
   },
   "outputs": [],
   "source": [
    "# 정확도 시각화\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, acc, 'b-', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r-', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oL_sPJiGyqaZ"
   },
   "outputs": [],
   "source": [
    "# 테스트 셋 평가\n",
    "model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1HC4MjdyugD"
   },
   "outputs": [],
   "source": [
    "# confusion matrix,# classification report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 모델 예측\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# 혼동 행렬 계산\n",
    "cm = confusion_matrix(y_test, y_pred_labels)\n",
    "\n",
    "# 혼동 행렬 시각화\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# 분류 리포트 출력\n",
    "cr = classification_report(y_test, y_pred_labels)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qNNN5ajzXVS"
   },
   "source": [
    "6. 성능 개량"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJXJVVYfzY9g"
   },
   "source": [
    "추가적인 성능을 높이는데는 드롭아웃, 배치 정규화, 밀집 연결층 추가 또는 삭제, 유닛 수 늘리기, 사전 학습 모델로 만들고 층 동결등 미세 조정 등이 있음."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
